{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/digit-recognizer/sample_submission.csv\n",
      "/kaggle/input/digit-recognizer/test.csv\n",
      "/kaggle/input/digit-recognizer/train.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing all required librabries **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Lambda, Flatten\n",
    "from keras.optimizers import Adam ,RMSprop\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import  backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Path of  test and train dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../input/digit-recognizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load train and test data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the training & test sets, skipping the header row with [1:]\n",
    "train = pd.read_csv(\"../input/digit-recognizer/train.csv\")\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= pd.read_csv(\"../input/digit-recognizer/test.csv\")\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n",
    "y_train = train.iloc[:,0].values.astype('int32') # only labels i.e targets digits\n",
    "X_test = test.values.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 7, 6, 9], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output variable is an integer from 0 to 9. This is a multiclass classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Convert train datset to (num_images, img_rows, img_cols) format \n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28)\n",
    "\n",
    "for i in range(6, 9):\n",
    "    plt.subplot(330 + (i+1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#expand 1 more dimention as 1 for colour channel gray\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28000, 28, 28, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing the digit images**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Standarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It is important preprocessing step. It is used to centre the data around zero mean and unit variance\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "\n",
    "def standardize(x): \n",
    "    return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One hot encoding of labels**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A one-hot vector is a vector which is 0 in most dimensions, and 1 in a single dimension. In this case, the nth digit will be represented as a vector which is 1 in the nth dimension.\n",
    "\n",
    "For example, 3 would be [0,0,0,1,0,0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train= to_categorical(y_train)\n",
    "num_classes = y_train.shape[1]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/matplotlib/text.py:1191: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(y_train[9])\n",
    "plt.plot(y_train[9])\n",
    "plt.xticks(range(10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Designing neural network architecture **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " #fix random seed for reproducibility\n",
    "seed = 43\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**linear Model **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import  Sequential\n",
    "from keras.layers.core import  Lambda , Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import BatchNormalization, Convolution2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets create a simple model from Keras Sequential layer.\n",
    "\n",
    "Lambda layer performs simple arithmetic operations like sum, average, exponentiation etc.\n",
    "\n",
    "In 1st layer of the model we have to define input dimensions of our data in (rows,columns,colour channel) format. (In theano colour channel comes first)\n",
    "\n",
    "Flatten will transform input into 1D array.\n",
    "Dense is fully connected layer that means all neurons in previous layers will be connected to all neurons in fully connected layer. In the last layer we have to specify output dimensions/classes of the model. Here it's 10, since we have to output 10 different digit labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape  (None, 28, 28, 1)\n",
      "output shape  (None, 10)\n"
     ]
    }
   ],
   "source": [
    "model= Sequential()\n",
    "model.add(Lambda(standardize,input_shape=(28,28,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"input shape \",model.input_shape)\n",
    "print(\"output shape \",model.output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making network ready for training we have to make sure to add below things:\n",
    "\n",
    "1. A loss function: to measure how good the network is\n",
    "\n",
    "2. An optimizer: to update network as it sees more data and reduce loss value\n",
    "\n",
    "3. Metrics: to monitor performance of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "model.compile(optimizer=RMSprop(lr=0.001),\n",
    " loss='categorical_crossentropy',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "gen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross Validation **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = X_train\n",
    "y = y_train\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.10, random_state=42)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches=gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "37800/37800 [==============================] - 111s 3ms/step - loss: 0.2407 - accuracy: 0.9338 - val_loss: 0.4734 - val_accuracy: 0.9100\n",
      "Epoch 2/3\n",
      "37800/37800 [==============================] - 111s 3ms/step - loss: 0.2169 - accuracy: 0.9410 - val_loss: 0.4587 - val_accuracy: 0.9092\n",
      "Epoch 3/3\n",
      "37031/37800 [============================>.] - ETA: 1s - loss: 0.2115 - accuracy: 0.9425"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=3, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convolution Neural Network **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "\n",
    "def get_cnn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7aae2516d3bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "model= get_cnn_model()\n",
    "model.optimizer.lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "34157/37800 [==========================>...] - ETA: 4:30 - loss: 0.0069 - accuracy: 0.9979"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is tehnique of showing slighly different or new images to neural network to avoid overfitting. And to achieve better generalization. In case you have very small dataset, you can use different kinds of data augmentation techniques to increase your data size. Neural networks perform better if you provide them more data.\n",
    "\n",
    "Different data aumentation techniques are as follows:\n",
    "\n",
    "Cropping\n",
    "Rotating\n",
    "Scaling\n",
    "Translating\n",
    "Flipping\n",
    "Adding Gaussian noise to input images etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen =ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "33325/37800 [=========================>....] - ETA: 5:57 - loss: 0.0128 - accuracy: 0.9960"
     ]
    }
   ],
   "source": [
    "#model.optimizer.lr=0.001\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding Batch Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def get_bn_model():\n",
    "    model = Sequential([\n",
    "        Lambda(standardize, input_shape=(28,28,1)),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Convolution2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "    model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "37800/37800 [==============================] - 4041s 107ms/step - loss: 0.0187 - accuracy: 0.9941 - val_loss: 4.1031e-04 - val_accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "model= get_bn_model()\n",
    "#model.optimizer.lr=0.01\n",
    "history=model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                    validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submitting the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test, verbose=0)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"DR.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
